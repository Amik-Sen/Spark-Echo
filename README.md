# Spark-Echo

- Learning spark and it fascinates me to see how everything that is created boils down to some code. Trying to follow the footstep towards making a cheap copy of the legacy, just for the learning experience. ğŸ˜„ğŸŠ
- I am actually keeping this in sync with whatever I am learning in the book. __"Spark : The definitive Guide"__

## What Spark problem I re-derived

## What I intentionally did NOT build

## Architecture diagram

## Execution flow walkthrough

## Example job with logs

## Learnings mapped to Spark internals

## Project Structure

```
minispark/
 â”œâ”€â”€ core/
 â”‚   â”œâ”€â”€ rdd/
 â”‚   â”‚   â”œâ”€â”€ RDD.java
 â”‚   â”‚   â”œâ”€â”€ Partition.java
 â”‚   â”‚   â”œâ”€â”€ Dependency.java
 â”‚   â”‚   â””â”€â”€ Lineage.java
 â”‚   â”œâ”€â”€ scheduler/
 â”‚   â”‚   â”œâ”€â”€ DAG.java
 â”‚   â”‚   â”œâ”€â”€ Stage.java
 â”‚   â”‚   â””â”€â”€ Scheduler.java
 â”‚   â”œâ”€â”€ executor/
 â”‚   â”‚   â”œâ”€â”€ Task.java
 â”‚   â”‚   â””â”€â”€ TaskRunner.java
 â”‚   â””â”€â”€ shuffle/
 â”‚       â”œâ”€â”€ ShuffleWriter.java
 â”‚       â””â”€â”€ ShuffleReader.java
 â”œâ”€â”€ examples/
 â”œâ”€â”€ README.md
 â””â”€â”€ docs/
```

### Phase 1 â€” Chapters: 1â€“3

- What all is covered in the chapters: 
  - What is Spark
  - Sparkâ€™s basic architecture
  - Driver / Executor model

- Your implementation
  - `SparkEchoContext`
  - Local â€œdriverâ€
  - Fixed thread pool = executors

### Phase 2 â€” Chapters: 4â€“6

- What all is covered in the chapters: 
  - RDD abstraction
  - Transformations vs Actions
  - Laziness

- Implementation
  - `RDD<T>`
  - `map`, `filter`, `flatMap`
  - `collect`, `count`

### Phase 3 â€” Chapters: 7â€“8

- What all is covered in the chapters: 
  - Partitions
  - Parallel execution

- Implementation
  - Each RDD has `List<Partition>`
  - Partition = slice of data
  - Tasks = (RDD, partition)

### Phase 4 â€” Chapters: 9â€“10

- What all is covered in the chapters: 
  - groupBy, reduceByKey
  - Wide vs narrow transformations
  - Shuffle boundaries

- Implementation
  - `reduceByKey`
  - Detect wide dependency
  - Break DAG into stages
  - Write shuffle output to disk (or memory map)

 ### Phase 5 â€” Chapters: 11â€“12

- What all is covered in the chapters: 
  - Caching
  - Fault tolerance
  - Lineage graph

- Implementation
  - `cache()` flag on RDD
  - Lineage DAG
  - Kill a task â†’ recompute from parents
 
### Phase 6 â€” Chapters: 13â€“15

- What all is covered in the chapters: 
  - Task retries
  - Simple scheduling policies

- Implementation
  - Retry failed task
  - Log stage/task execution
  - Simple FIFO scheduler
 
### Phase 7 â€” Chapters: 16â€“18

- What all is covered in the chapters: 
  - groupBy, reduceByKey
  - Wide vs narrow transformations
  - Shuffle boundaries

- Implementation
  - `reduceByKey`
  - Detect wide dependency
  - Break DAG into stages
  - Write shuffle output to disk (or memory map)
 
### Phase 8 â€” Chapters: 19+

- What all is covered in the chapters: 
  - Streaming = continuous micro-batch
  - Each batch = normal Spark job
  - Same DAG, same scheduler, repeated over time
  - Fault tolerance via replay + lineage

- Implementation
  - `StreamingContext`
  - DStream abstraction
  - Supported operations
    - map
    - filter
    - reduceByKey
    - window(windowSize, slideInterval)
    - foreachBatch(RDD -> action)



